// proto/placement.proto
syntax = "proto3";

package vectron.placementdriver.v1;

option go_package = "github.com/pavandhadge/vectron/shared/proto/placementdriver";
// ===============================================
// Placement Driver — The Brain of Vectron
// ===============================================

service PlacementService {
  // Get worker address for a collection + optional vector ID (for consistent hashing)
  rpc GetWorker(GetWorkerRequest) returns (GetWorkerResponse) {}

  // Worker registers itself on startup
  rpc RegisterWorker(RegisterWorkerRequest) returns (RegisterWorkerResponse) {}

  // Worker sends heartbeat (every 5s)
  rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse) {}

  // List all workers (for monitoring)
  rpc ListWorkers(ListWorkersRequest) returns (ListWorkersResponse) {}

  rpc ListWorkersForCollection(ListWorkersForCollectionRequest) returns (ListWorkersForCollectionResponse) {}

  // Admin: drain a worker (move shards away, stop new assignments)
  rpc DrainWorker(DrainWorkerRequest) returns (DrainWorkerResponse) {}
  // Admin: remove a worker (only when it has no shards)
  rpc RemoveWorker(RemoveWorkerRequest) returns (RemoveWorkerResponse) {}

  // Admin: force rebalance (future)
  rpc Rebalance(RebalanceRequest) returns (RebalanceResponse) {}
  // Collection management
  rpc CreateCollection(CreateCollectionRequest) returns (CreateCollectionResponse) {}
  rpc ListCollections(ListCollectionsRequest) returns (ListCollectionsResponse) {}
  rpc DeleteCollection(DeleteCollectionRequest) returns (DeleteCollectionResponse) {}
  rpc GetCollectionStatus(GetCollectionStatusRequest) returns (GetCollectionStatusResponse) {}
  rpc GetLeader(GetLeaderRequest) returns (GetLeaderResponse) {}
}

// ===============================================
// Messages
// ===============================================

message GetLeaderRequest {}

message GetLeaderResponse {
  string leader_address = 1;
}

message GetWorkerRequest {
  // Collection name (required)
  string collection = 1;

  // Optional: vector ID for consistent hashing
  // If empty → use collection-level sharding
  string vector_id = 2;
}

message GetWorkerResponse {
  // Full address: "10.0.0.42:6201" or "worker-3.internal:6201"
  string grpc_address = 1;

  // Optional: shard info
  uint32 shard_id = 2;
  // Monotonic shard epoch for fencing
  uint64 shard_epoch = 3;
  // Lease expiry for routing (unix millis)
  int64 lease_expiry_unix_ms = 4;
}

message RegisterWorkerRequest {
  string grpc_address = 1;
  string raft_address = 2;
  repeated string capabilities = 3; // ["gpu", "large-memory"]
  int64 timestamp = 4;

  // Capacity information for capacity-weighted placement
  int32 cpu_cores = 5;        // Number of CPU cores available
  int64 memory_bytes = 6;     // Total memory in bytes
  int64 disk_bytes = 7;       // Total disk space in bytes

  // Failure domain information for fault-tolerant placement
  string rack = 8;            // Rack identifier (e.g., "rack-01")
  string zone = 9;            // Zone/availability zone (e.g., "us-east-1a")
  string region = 10;         // Region (e.g., "us-east-1")
}

message RegisterWorkerResponse {
  string worker_id = 1; // assigned by placement driver

  bool success = 2;
}

message ShardLeaderInfo {
  uint64 shard_id = 1;

  uint64 leader_id = 2;
}

// ShardMembershipInfo contains membership details for a shard.
message ShardMembershipInfo {
  uint64 shard_id = 1;
  uint64 config_change_id = 2;
  repeated uint64 node_ids = 3;
}

// ShardProgressInfo reports per-shard applied index for fencing moves.
message ShardProgressInfo {
  uint64 shard_id = 1;
  uint64 applied_index = 2;
  uint64 shard_epoch = 3;
}

// ShardLeaderTransferAck confirms leader transfer completion.
message ShardLeaderTransferAck {
  uint64 shard_id = 1;
  uint64 from_node_id = 2;
  uint64 to_node_id = 3;
  uint64 shard_epoch = 4;
  int64 timestamp_unix_ms = 5;
}

// ShardMetrics contains per-shard performance metrics for hot-shard detection
message ShardMetrics {
  uint64 shard_id = 1;
  float queries_per_second = 2;  // Query rate for this shard
  int64 vector_count = 3;        // Number of vectors in this shard
  float avg_latency_ms = 4;      // Average query latency in milliseconds
}

message HeartbeatRequest {
  string worker_id = 1;

  int64 timestamp = 2;

  // Optional metrics

  int64 vector_count = 3;

  int64 memory_bytes = 4;

  repeated ShardLeaderInfo shard_leader_info = 5;

  // Load metrics for load-aware placement

  float cpu_usage_percent = 6; // 0-100

  float memory_usage_percent = 7; // 0-100

  float disk_usage_percent = 8; // 0-100

  float queries_per_second = 9; // Current query rate

  int64 active_shards = 10; // Number of shards being served

  // Per-shard metrics for hot-shard detection
  repeated ShardMetrics shard_metrics = 11;

  // Shard replicas currently running on this worker (used for move orchestration)
  repeated uint64 running_shards = 12;

  // Shard membership info (reported by leaders only)
  repeated ShardMembershipInfo shard_membership = 13;
  // Shard progress info (applied index per shard on this worker)
  repeated ShardProgressInfo shard_progress = 14;
  // Leader transfer acknowledgements
  repeated ShardLeaderTransferAck leader_transfer_acks = 15;
}

message HeartbeatResponse {
  // If false → worker is considered dead
  bool ok = 1;
  // Optional: config updates
  string message = 2;
  // Monotonic epoch for shard assignments
  uint64 assignments_epoch = 3;
}

message ListWorkersRequest {}

message ListWorkersResponse {
  repeated WorkerInfo workers = 1;
}

message ListWorkersForCollectionRequest {
  string collection = 1;
}

message ListWorkersForCollectionResponse {
  repeated string grpc_addresses = 1;
}

enum WorkerState {
  WORKER_STATE_UNKNOWN = 0;
  WORKER_STATE_JOINING = 1;
  WORKER_STATE_READY = 2;
  WORKER_STATE_DRAINING = 3;
}

message WorkerInfo {
  string worker_id = 1;
  string grpc_address = 2;
  string raft_address = 3;
  repeated string collections = 4;
  int64 last_heartbeat = 5;
  bool healthy = 6;
  map<string, string> metadata = 7;
  WorkerState state = 8;
}

message DrainWorkerRequest {
  string worker_id = 1;
}

message DrainWorkerResponse {
  bool success = 1;
}

message RemoveWorkerRequest {
  string worker_id = 1;
}

message RemoveWorkerResponse {
  bool success = 1;
}

message RebalanceRequest {
  // Future use
}

message RebalanceResponse {
  bool started = 1;
}

message CreateCollectionRequest {
  string name = 1;
  int32 dimension = 2;
  string distance = 3;
}

message CreateCollectionResponse {
  bool success = 1;
}

message ListCollectionsRequest {}

message ListCollectionsResponse {
  repeated string collections = 1;
}

message DeleteCollectionRequest {
  string name = 1;
}

message DeleteCollectionResponse {
  bool success = 1;
}

message GetCollectionStatusRequest {
  string name = 1;
}

message GetCollectionStatusResponse {
  string name = 1;
  int32 dimension = 2;
  string distance = 3;
  repeated ShardStatus shards = 4;
}

message ShardStatus {
  uint32 shard_id = 1;
  repeated uint64 replicas = 2;
  uint64 leader_id = 3;
  bool ready = 4;
}

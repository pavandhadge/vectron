Core Algorithms and Data Structures—Vectron’s core algorithms span four areas: shard routing, Raft-based replication, HNSW approximate search, and distributed aggregation. These algorithms are implemented with data structures chosen for performance, correctness, and concurrency safety.

Shard routing is driven by key range partitioning. Each collection is divided into shards, and each shard owns a range within a hashed keyspace derived from vector IDs. The Placement Driver stores the shard map, including ranges, replica sets, leaders, and epochs. The Gateway uses this metadata to route operations to the correct shard. Routing correctness is enforced by shard epochs: if the Gateway’s cached epoch is stale, the Worker returns a stale‑shard error, forcing the Gateway to refresh routing metadata. This ensures that routing remains correct even during rebalancing or membership changes.

Write replication is implemented at the shard level using Raft. Each write is encoded into a command with type, ID, vector, and metadata. The Worker proposes this command to the shard’s Raft log. Once committed, the shard’s state machine applies the command, storing the vector in PebbleDB and updating the HNSW index. The Raft log provides deterministic ordering, and the state machine ensures that replicas converge to the same state. Commands are encoded in a versioned binary format to support schema evolution and to reduce decoding overhead in hot paths.

The HNSW index provides approximate nearest‑neighbor search. It is implemented as a layered graph where each node represents a vector and maintains neighbor lists per layer. Insertion chooses a random maximum layer for each node and connects the node to neighbors found through greedy traversal. Search begins at the highest layer and descends to the base layer, maintaining a candidate list whose size is controlled by efSearch. This parameter governs the recall‑latency trade‑off. Vectron also supports two‑stage search, where an initial candidate list is generated using a smaller ef and then refined using higher‑precision scoring. The index supports cosine or euclidean distance, optional vector normalization, and optional quantization to int8, with a retained float representation when exact reranking is required.

Distributed search aggregation is performed in the Gateway. When multiple workers return results, the Gateway uses a min‑heap to maintain the global topK. Candidate limits are applied to reduce aggregation cost before reranking. The aggregation algorithm is deterministic with respect to scores and ensures that the final response respects topK constraints. This is complemented by in-flight request deduplication: concurrent identical search requests are coalesced, reducing redundant computation under bursty load.

Supporting data structures include sharded caches for search responses, worker lists, and routing metadata. Sharding is used to reduce lock contention under concurrent access. The HNSW implementation uses internal maps to convert between external IDs and internal numeric IDs, and maintains deletion maps to support logical removal. Object pools are used for vector buffers and heap items to reduce allocation overhead and garbage collection pressure, which is significant in high‑QPS search workloads.

In combination, these algorithms provide a coherent pipeline: routing selects shards; Raft ensures write durability; HNSW provides approximate search; aggregation merges distributed results. The data structures reinforce this pipeline by minimizing contention and ensuring deterministic behavior. This integration of algorithms and structures is central to Vectron’s performance and correctness characteristics.
